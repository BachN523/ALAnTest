{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import os                                   \nimport numpy as np                                     \nfrom scipy import optimize, stats                      \nimport pandas as pd\nimport time",
      "metadata": {},
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# for i in range(16):\n\n#path for main direc\npath = \"/Users/nicoledawney/Desktop/imaris_statistics/\"\n#address of desired end location\noutput_path = \"/Users/nicoledawney/Desktop/ALAn_input\"\nfolder = os.listdir(path) #returns list of folders in directory",
      "metadata": {},
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "folder",
      "metadata": {},
      "execution_count": 3,
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Etoposide_48hrs_fixedat0_b12_2022-07-26_Nicole's protocol_08.37.11_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_fixedat0_b4_2022-07-26_Nicole's protocol_08.24.44_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_24hrsEtop_b10_2022-07-25_Nicole's protocol_16.26.39_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_fixedat0_b13_2022-07-26_Nicole's protocol_08.38.55_Admin_Statistics\",\n",
              " '.DS_Store',\n",
              " \"Etoposide_48hrs_fixedat0_b9_2022-07-26_Nicole's protocol_08.32.34_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_fixedat0_b6_2022-07-26_Nicole's protocol_08.27.56_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_24hrsEtop_b2_2022-07-25_Nicole's protocol_16.13.08_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_24hrsEtop_b12_2022-07-25_Nicole's protocol_16.29.54_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_fixedat0_b3_2022-07-26_Nicole's protocol_08.23.00_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_24hrsEtop_b3_2022-07-25_Nicole's protocol_16.14.47_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_24hrsEtop_b4_2022-07-25_Nicole's protocol_16.16.23_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_24hrsEtop_b8_2022-07-25_Nicole's protocol_16.23.14_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_fixedat0_b11_2022-07-26_Nicole's protocol_08.35.36_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_fixedat0_b5_2022-07-26_Nicole's protocol_08.26.25_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_fixedat0_b7_2022-07-26_Nicole's protocol_08.29.22_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_24hrsEtop_b16_2022-07-25_Nicole's protocol_16.36.21_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_24hrsEtop_b9_2022-07-25_Nicole's protocol_16.25.09_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_24hrsEtop_b11_2022-07-25_Nicole's protocol_16.28.20_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_fixedat0_b1_2022-07-26_Nicole's protocol_08.19.47_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_fixedat0_b8_2022-07-26_Nicole's protocol_08.30.52_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_fixedat0_b16_2022-07-26_Nicole's protocol_08.43.57_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_fixedat0_b10_2022-07-26_Nicole's protocol_08.34.04_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_24hrsEtop_b6_2022-07-25_Nicole's protocol_16.19.58_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_24hrsEtop_b7_2022-07-25_Nicole's protocol_16.21.40_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_fixedat0_b15_2022-07-26_Nicole's protocol_08.42.01_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_24hrsEtop_b15_2022-07-25_Nicole's protocol_16.34.28_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_24hrsEtop_b14_2022-07-25_Nicole's protocol_16.32.57_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_24hrsEtop_b13_2022-07-25_Nicole's protocol_16.31.28_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_fixedat0_b14_2022-07-26_Nicole's protocol_08.40.25_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_24hrsEtop_b1_2022-07-25_Nicole's protocol_16.11.29_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_24hrsEtop_b5_2022-07-25_Nicole's protocol_16.18.10_Admin_Statistics\",\n",
              " \"Etoposide_48hrs_fixedat0_b2_2022-07-26_Nicole's protocol_08.21.18_Admin_Statistics\"]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "def subfolder_name_lists(folder_address, list_of_folders, output_path):\n    \n    labels = []\n    list_of_folders.sort()\n    list_of_folders = [i for i in list_of_folders if i != '.DS_Store'] #remove unwanted element in list\n#     print(list_of_folders)\n    for item in list_of_folders:\n        x = item.split('_')\n#         print(x)\n        label = x[0] + x[1] +x[2] +x[3] #take only the desired labels for the collated file\n                                    #in this case: e.g. \"100k + 1hr + a1\"\n#         print(str(label))\n        labels.append(str(label)) #append each label to a list for later use\n#     print(labels)\n    \n    positions = [] #list of position files names\n    volumes = [] #list of volume file names\n    subfolder_addresses = [] #list of subfolder paths\n    for item in list_of_folders:\n#         item = list_of_folders[i+1]\n        subfolder = folder_address + \"/\" + item  #subfolder address\n        subfolder_addresses.append(subfolder)\n        files = os.listdir(subfolder) #returns list of files in subfolder\n        #next two lines will assign position and volume csv file names\n        position = [f for f in files if f[-12:] == \"Position.csv\"]\n        volume = [f for f in files if f[-10:] == \"Volume.csv\"]\n        #append position/volume file names into their respective lists\n        positions.append(position)\n        volumes.append(volume)\n#         print(position,volume)\n    #next two lines transform the lists of lists of strings into lists of strings for ease of use later\n    positions = [''.join(i) for i in positions]\n    volumes = [''.join(i) for i in volumes]\n    \n    #need to go into folder then subfolder then pd.read_excel the desired csv, then append to a list of dfs\n    #use list of subfolder addresses to bypass first step, then just say for each subfolder address add on our\n    #position of volume files suffix and pd.read_excel that sucker\n    position_dfs = []\n    volume_dfs = []\n    \n    for i in range(len(subfolder_addresses)):\n        \n        #read in position csv's as data frames and append to list\n        position_address = subfolder_addresses[i] + \"/\" + positions[i]\n        df = pd.read_csv(position_address, encoding = \"utf-8\", skiprows = 3)\n        df = df.drop(['Unit', \"Category\", \"Collection\", \"Time\", \"CellID\", \"ID\", \"Unnamed: 9\"], axis = 1) #dropping unwanted columns\n        position_dfs.append(df)\n        \n        #read in volume csv's as data frames and append to list\n        volume_address = subfolder_addresses[i] + \"/\" + volumes[i]\n        volume_dfs.append(pd.read_csv(volume_address, encoding = \"utf-8\", skiprows = 3))\n    \n    #taking the one column we want from the volume csv's and merging it with the processed position csv's\n    merged_dfs = []\n    for i in range(len(volume_dfs)):\n        df = volume_dfs[i]\n        sub_df = df[\"Nucleus Volume\"] #single column we want\n        p_df = position_dfs[i]\n        merged_df = pd.concat([p_df, sub_df], axis=1)\n        merged_dfs.append(merged_df)\n        #saves collated data as csv's in desired location\n        merged_df.to_csv(output_path + '/' + labels[i] + '.csv', index = False)\n        \n    return merged_dfs, labels",
      "metadata": {},
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "toc = time.time()\nsubfolder_name_lists(path, folder, output_path)\ntic = time.time()\nprint(tic-toc)",
      "metadata": {},
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "0.39849090576171875\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}