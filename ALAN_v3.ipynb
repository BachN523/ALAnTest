{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated Layer Analysis Version 3\n",
    "# First developed by Nicole S Dawney, Christian Cammarota and Dan Bergstralh 2020-2022 at the University of Rochester\n",
    "# This version and annotations written by Tara M Finegan September 2023 at the University of Missouri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "# The code in this cell imports all necessary Python packages and sets Plots to be interactive in the notebook \n",
    "\n",
    "import os                                   \n",
    "import numpy as np                            \n",
    "import skimage.io as io            \n",
    "from scipy import optimize, stats                      \n",
    "import pandas as pd                             \n",
    "import math\n",
    "import inspect\n",
    "import time\n",
    "from scipy import signal\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt   \n",
    "from matplotlib import colors\n",
    "%matplotlib notebook\n",
    "\n",
    "from skimage import filters, measure, morphology, segmentation, util \n",
    "from skimage.filters import try_all_threshold\n",
    "from skimage.feature import peak_local_max, canny        \n",
    "from scipy import optimize, ndimage              \n",
    "from skimage.measure import label                 \n",
    "from skimage.measure import regionprops           \n",
    "from skimage.segmentation import clear_border, watershed     \n",
    "from skimage.color import label2rgb, rgb2gray              \n",
    "from skimage.morphology import remove_small_objects, remove_small_holes  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time to read in all of the data in this folder is:\n",
      "0.9113261699676514\n",
      "The name of the files read in are:\n",
      "['200K1hra1', '200K1hra2', '200K1hra3', '200K1hra4']\n",
      "The dimensions of the 3 lists (list_of_names), (list_of_dfs) and (list_of_unshuffled_images) are:\n",
      "4 4 4\n",
      "The dimensions of the lists are the same- you are okay to proceed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3\n",
    "# The code in this cell reads in the input data, times this process and prints the time it takes to read in the data, \n",
    "# and a list of names\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "path = \"/Users/tarafinegan/Desktop/ALAninput/\"\n",
    "files = os.listdir(path) \n",
    "spreadsheet_files = [f for f in files if f[-3:] == 'csv']\n",
    "images = [f for f in files if f[-3:] == 'tif']\n",
    "\n",
    "list_of_image_names = [sub[:-4] for sub in images]\n",
    "spreadsheet_files.sort()\n",
    "images.sort()\n",
    "list_of_spreadsheet_names = [sub[:-4] for sub in spreadsheet_files] \n",
    "unmatched_spreadsheets = [i for i in list_of_spreadsheet_names if i[:] not in list_of_image_names]\n",
    "unmatched_images = [i for i in list_of_image_names if i[:] not in list_of_spreadsheet_names]\n",
    "\n",
    "if len(unmatched_spreadsheets) > 0:  \n",
    "    for i in range(len(unmatched_spreadsheets)):\n",
    "        list_of_spreadsheet_names.remove(unmatched_spreadsheets[i]) \n",
    "spreadsheet_suffix = '.csv'\n",
    "aligned_spreadsheet_files = [sub + spreadsheet_suffix for sub in list_of_spreadsheet_names]\n",
    "aligned_spreadsheet_files.sort()\n",
    "\n",
    "if len(unmatched_images) > 0:\n",
    "    for i in range(len(unmatched_images)):\n",
    "        list_of_image_names.remove(unmatched_images[i])\n",
    "image_suffix = '.tif'\n",
    "aligned_images = [sub + image_suffix for sub in list_of_image_names]\n",
    "aligned_images.sort()\n",
    "\n",
    "list_of_dfs = []\n",
    "for item in aligned_spreadsheet_files:\n",
    "    list_of_dfs.append(pd.read_csv(path + item))\n",
    "    \n",
    "list_of_unshuffled_images = []\n",
    "\n",
    "for item in aligned_images:\n",
    "    list_of_unshuffled_images.append(io.imread(path + item))\n",
    "\n",
    "tic = time.time()\n",
    "print('The time to read in all of the data in this folder is:')\n",
    "print(tic-toc)\n",
    "\n",
    "list_of_names = [f[:-4] for f in aligned_images]\n",
    "print('The name of the files read in are:')\n",
    "print(list_of_names)\n",
    "print('The dimensions of the 3 lists (list_of_names), (list_of_dfs) and (list_of_unshuffled_images) are:')\n",
    "print(len(list_of_names), len(list_of_dfs), len(list_of_unshuffled_images))\n",
    "\n",
    "if (len(list_of_names)==len(list_of_dfs)==len(list_of_unshuffled_images)):\n",
    "    print('The dimensions of the lists are the same- you are okay to proceed!')\n",
    "else:\n",
    "    print('The dimensions of the lists are not the same- something has gone wrong')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     2,
     11,
     187
    ]
   },
   "outputs": [],
   "source": [
    "# Cell 4\n",
    "# The code in this cell defines all of the functions of ALAn.\n",
    "# An explanation of these definitions can be found in the ALAn README.\n",
    "\n",
    "def image_shuffle(image):\n",
    "    a, b, c, d = image.shape\n",
    "    if a == 512:\n",
    "        xloc = 0\n",
    "        if b == 512:\n",
    "            yloc = 1\n",
    "            if c >4:\n",
    "                zloc = 2\n",
    "                colloc = 3\n",
    "            else:\n",
    "                zloc = 3\n",
    "                colloc = 2\n",
    "        elif c == 512:\n",
    "            yloc = 2\n",
    "            if b > 4:\n",
    "                zloc = 1\n",
    "                colloc = 3\n",
    "            else:\n",
    "                zloc = 3\n",
    "                colloc = 1\n",
    "        else:\n",
    "            yloc = 3\n",
    "            if b > 4:\n",
    "                zloc = 1\n",
    "                colloc = 2\n",
    "            else:\n",
    "                zloc = 2\n",
    "                colloc = 1\n",
    "    elif b == 512:\n",
    "        xloc = 1\n",
    "        if c == 512:\n",
    "            yloc = 2\n",
    "            if a > 4:\n",
    "                zloc = 0\n",
    "                colloc = 3\n",
    "            else:\n",
    "                zloc = 3\n",
    "                colloc = 0\n",
    "        else:\n",
    "            yloc = 3\n",
    "            if a > 4:\n",
    "                zloc = 0\n",
    "                colloc = 2\n",
    "            else:\n",
    "                zloc = 2\n",
    "                colloc = 0\n",
    "    else:\n",
    "        xloc = 2\n",
    "        yloc = 3\n",
    "        if a > 4:\n",
    "            zloc = 0\n",
    "            colloc = 1\n",
    "        else:\n",
    "            zloc = 1\n",
    "            colloc = 0\n",
    "    return np.transpose(image, (zloc, colloc, xloc, yloc))\n",
    "\n",
    "def get_layer_position(df, image):\n",
    "    image = image_shuffle(image)\n",
    "    num_z, num_c, num_x, num_y = image.shape\n",
    "    df.columns = ['x', 'y', 'z', 'vol', 'positions']\n",
    "    x_max = df['positions'][0]\n",
    "    y_max = df['positions'][1]\n",
    "    z_max = df['positions'][2]\n",
    "    x_min = df['positions'][3]\n",
    "    y_min = df['positions'][4]\n",
    "    z_min = df['positions'][5]\n",
    "    slice_heights = np.linspace(0, z_max-z_min, num = num_z)\n",
    "    return (x_max, y_max, z_max, x_min, y_min, z_min, slice_heights)\n",
    "\n",
    "def local_density(df, image, **kwargs):\n",
    "    x_max, y_max, z_max, x_min, y_min, z_min, slice_heights = get_layer_position(df, image)\n",
    "    box_radius = kwargs.get('box_radius', (x_max-x_min)/2) \n",
    "    df_cleared = clear_debris(df)\n",
    "    xcent= (x_min+x_max)/2 \n",
    "    ycent= (y_min+y_max)/2 \n",
    "    xmin_box, xmax_box = xcent - box_radius, xcent + box_radius\n",
    "    ymin_box, ymax_box = ycent- box_radius, ycent + box_radius \n",
    "    df_box = df_cleared[(df_cleared['x'].values >= xmin_box)& \n",
    "                        (df_cleared['x'].values <= xmax_box)&\n",
    "                        (df_cleared['y'].values >= ymin_box)&\n",
    "                        (df_cleared['y'].values <= ymax_box)] \n",
    "    number_of_cells_in_box = len(df_box) \n",
    "    box_density = (number_of_cells_in_box / (4*box_radius**2))*1000\n",
    "    return number_of_cells_in_box, box_density\n",
    "\n",
    "\n",
    "def clear_debris(df, **kwargs):\n",
    "    df.columns = ['x', 'y', 'z', 'vol', 'positions']\n",
    "    plot = kwargs.get('plot', False)\n",
    "    save_name = kwargs.get('save_name', False)\n",
    "    vols = df['vol'].values \n",
    "    bottom_vol = np.mean(vols)- (1.5*np.std(vols)) \n",
    "    df_cleared = df[df['vol']>=bottom_vol] \n",
    "    if plot == True: \n",
    "        bins = np.linspace(np.min(vols), np.max(vols), num = 100)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(vols, bins = bins, alpha = 1, label= 'Debris')\n",
    "        ax.hist(df_cleared['vol'].values, bins = bins, alpha = 1, label = 'Cells')\n",
    "        ax.legend(loc = 'upper right')\n",
    "        ax.set_ylabel('Number of cells')\n",
    "        ax.set_xlabel('Nucleus volume ($\\mu$m$^3$)')\n",
    "        ax.axvline(x = bottom_vol, c='k', linestyle = '--')\n",
    "        fig.show\n",
    "        if save_name != False: \n",
    "            plt.savefig(save_name + '.pdf', bbox_inches = 'tight', pad_inches = 1)\n",
    "    return(df_cleared)\n",
    "\n",
    "\n",
    "def layer_height_actin(df, image, **kwargs):\n",
    "    image = image_shuffle(image)\n",
    "    x_max, y_max, z_max, x_min, y_min, z_min, slice_heights = get_layer_position(df, image)\n",
    "    plot = kwargs.get('plot', False)\n",
    "    save_name = kwargs.get('save_name', False)\n",
    "    actin_channel = kwargs.get('actin_channel', 1)\n",
    "    section = kwargs.get('section', (False, False, False, False))\n",
    "    invert = kwargs.get('invert', False)\n",
    "    bottom, top, left, right = section\n",
    "    \n",
    "    \n",
    "    if top == False:\n",
    "        xy_proj_actin = np.sum(np.sum(image, axis = 3), axis = 2)[:,actin_channel].copy()\n",
    "    else:\n",
    "        xy_proj_actin = np.sum(np.sum(image[:,:,bottom:top,left:right], axis = 3), axis = 2)[:,actin_channel].copy()\n",
    "    \n",
    "    if invert == True:\n",
    "        xy_proj_actin = xy_proj_actin.copy()[::-1] \n",
    "        \n",
    "    norm_intensities_actin = (xy_proj_actin-np.min(xy_proj_actin))/np.max(xy_proj_actin-np.min(xy_proj_actin))\n",
    "    \n",
    "    actin_peak = slice_heights[np.argwhere(norm_intensities_actin == np.max(norm_intensities_actin))][0][0] \n",
    "    df_cleared = clear_debris(df)\n",
    "    density = len(df_cleared)/(x_max-x_min)**2*1000\n",
    "    if density <=2:\n",
    "        bot_cutoff = 0.5\n",
    "        top_cutoff = 0.6\n",
    "    elif density>=6:\n",
    "        bot_cutoff = 0.2\n",
    "        top_cutoff = 0.8\n",
    "    else:\n",
    "        bot_cutoff = 0.5-0.3*(density-2)/4\n",
    "        top_cutoff = 0.6+0.2*(density-2)/4\n",
    "    print(density, bot_cutoff, top_cutoff)\n",
    "    min_actin_slice = np.argwhere(norm_intensities_actin >= bot_cutoff)[0][0]\n",
    "    max_actin_slice = np.argwhere(norm_intensities_actin >= top_cutoff)[-1][0] \n",
    "    min_layer_height = slice_heights[min_actin_slice]\n",
    "    max_layer_height = slice_heights[max_actin_slice] \n",
    "    layer_height = max_layer_height-min_layer_height\n",
    "    actin_intensity_top = norm_intensities_actin[max_actin_slice] \n",
    "    \n",
    "    if (plot == True):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(slice_heights, norm_intensities_actin, c='cornflowerblue')\n",
    "        ax.set_ylabel('Actin Intensity (A.U.)')\n",
    "        ax.set_xlabel('Z-Position ($\\mu$m)')\n",
    "        ax.axvline(x = min_layer_height, c='k', linestyle = '--', label = 'Layer Bounds')\n",
    "        ax.axvline(x = max_layer_height, c = 'k', linestyle = '--')\n",
    "        ax.axvline(x = np.max(slice_heights), c = 'r', linestyle = '--')\n",
    "        ax.legend(loc='upper right')\n",
    "        ax.set_ylim([0,1.1])\n",
    "        ax.set_xlim([0, 30])\n",
    "        if save_name != False:\n",
    "            plt.savefig(save_name + '.pdf', bbox_inches = 'tight', pad_inches = 1)\n",
    "    return (min_layer_height, max_layer_height, layer_height, actin_peak, norm_intensities_actin)\n",
    "\n",
    "def smooth_array(array, **kwargs):\n",
    "    number_to_smooth = kwargs.get('window_size', 3)\n",
    "    window = np.ones(number_to_smooth)/number_to_smooth \n",
    "    new_array = np.convolve(array, window, mode='same') \n",
    "    return new_array\n",
    "\n",
    "def find_shoulders(df, image, **kwargs):\n",
    "    image = image_shuffle(image)\n",
    "    plot = kwargs.get('plot', False)\n",
    "    save_name = kwargs.get('save_name', False)\n",
    "    actin_channel  = kwargs.get('actin_channel', 1)\n",
    "    section = kwargs.get('section', (False, False, False, False))\n",
    "    invert = kwargs.get('invert', False)\n",
    "    bottom, top, left, right = section\n",
    "    \n",
    "    x_max, y_max, z_max, x_min, y_min, z_min, slice_heights = get_layer_position(df, image)\n",
    "    min_layer_height, max_layer_height, layer_height, actin_peak, norm_intensities_actin = layer_height_actin(df, image, actin_channel = actin_channel, invert = invert, section = section)\n",
    "    \n",
    "    if top == False:\n",
    "        xy_proj_actin = np.sum(np.sum(image, axis = 3), axis = 2)[:,actin_channel].copy()\n",
    "    else:\n",
    "        xy_proj_actin = np.sum(np.sum(image[:,:,bottom:top,left:right], axis = 3), axis = 2)[:,actin_channel].copy()\n",
    "    \n",
    "    if invert == True:\n",
    "        xy_proj_actin = xy_proj_actin.copy()[::-1]\n",
    "                                                                 \n",
    "    \n",
    "    norm_intensities_actin = (xy_proj_actin-np.min(xy_proj_actin))/np.max(xy_proj_actin-np.min(xy_proj_actin))\n",
    "    actin_profile_derivative = smooth_array(np.diff(norm_intensities_actin), window_size = 5)\n",
    "    peaks = signal.find_peaks(actin_profile_derivative, prominence = 0.008)\n",
    "    \n",
    "    if len(peaks[0])>=2:\n",
    "        equivalence = peaks[1]['prominences'][1]/peaks[1]['prominences'][0]\n",
    "    else:\n",
    "        equivalence = 'undef'\n",
    "    \n",
    "    if plot == True or save_name != False:\n",
    "        fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (7,7))\n",
    "        ax.plot(slice_heights, norm_intensities_actin, 'red', label = 'Actin Profile')\n",
    "        ax.set_ylabel('Actin Intensity (A.U.)')\n",
    "        ax.set_xlabel('Z-Position ($\\mu$m)')\n",
    "        ax2=ax.twinx()\n",
    "        ax.set_xlim(0, 30)\n",
    "        ax2.plot(slice_heights[:-1] + (z_max-z_min)/(2*len(slice_heights)), actin_profile_derivative, 'steelblue', label = 'Actin Derivative')\n",
    "        ax2.set_xlabel('Z-Position ($\\mu$m)')\n",
    "        ax2.set_ylabel('Actin Profile 1$^{st}$ Derivative (A.U. / $\\mu$m)')\n",
    "        ax.axvline(x = min_layer_height, c='k', linestyle = '--', label = 'Layer Bounds')\n",
    "        ax.axvline(x = max_layer_height, c = 'k', linestyle = '--')\n",
    "        fig.tight_layout()\n",
    "        fig.show()\n",
    "        if save_name != False:\n",
    "            plt.savefig(save_name + '.pdf', bbox_inches = 'tight', pad_inches = 1)\n",
    "    \n",
    "    return (equivalence, len(peaks[0]))\n",
    "\n",
    "def gaussian_fit(x, A, B, C):\n",
    "    return A * np.exp(-1 * ((x - B) / C) ** 2)\n",
    "\n",
    "def double_gaussian_fit(x, A, B, C, D, E, F):\n",
    "    return A * np.exp(-1 * ((x - B) / C) ** 2) + D * np.exp(-1 * ((x - E) / F) ** 2)\n",
    "\n",
    "def nuclei_distribution(df, image, **kwargs):\n",
    "    plot = kwargs.get('plot', False)\n",
    "    save_name = kwargs.get('save_name', False)\n",
    "    section = kwargs.get('section', (False, False, False, False))\n",
    "    invert = kwargs.get('invert', False)\n",
    "    actin_channel = kwargs.get('actin_channel', 1)\n",
    "    bottom, top, left, right = section\n",
    "    x_max, y_max, z_max, x_min, y_min, z_min, slice_heights = get_layer_position(df, image)\n",
    "    min_layer_height, max_layer_height, layer_height, actin_peak, norm_intensities_actin = layer_height_actin(df, image, actin_channel = actin_channel, invert = invert, section = section)\n",
    "    \n",
    "    if top != False:\n",
    "        xlow = (x_max-x_min)*left/512+x_min\n",
    "        xhigh = (x_max-x_min)*right/512+x_min\n",
    "        ylow = (y_max-y_min)*bottom/512+y_min\n",
    "        yhigh = (y_max-y_min)*top/512+y_min\n",
    "    df_cleared = clear_debris(df)\n",
    "    if top != False:\n",
    "        df_cleared = df_cleared[(df_cleared['x'].values >= xlow)& \n",
    "                               (df_cleared['x'].values <= xhigh)&\n",
    "                               (df_cleared['y'].values >= ylow)&\n",
    "                               (df_cleared['y'].values <= yhigh)]\n",
    "    \n",
    "    if invert == True:\n",
    "        zs = z_max - df_cleared['z'].values\n",
    "    else:\n",
    "        zs = df_cleared['z'].values - z_min\n",
    "    bins = np.linspace(0, 50, 51)\n",
    "    bins_fit = np.linspace(0, 50, 1000)\n",
    "    counts, bins_aux = np.histogram(zs, bins = bins)\n",
    "    counts_to_fit = smooth_array(counts)\n",
    "    \n",
    "    peak_height_guess = np.max(counts_to_fit)\n",
    "    peak_loc_guess = bins[np.argwhere(counts_to_fit==peak_height_guess)[0][0]]\n",
    "            \n",
    "            \n",
    "    p0_double = [peak_height_guess, peak_loc_guess, 2, 30, 2*peak_loc_guess, 5]\n",
    "    p0_single = [peak_height_guess, peak_loc_guess, 2]\n",
    "    print(p0_double, p0_single)\n",
    "    bounds_double = ([0, 1, 1, 0, 1, 1], [400, 80, 15, 400, 80, 15])\n",
    "    bounds_single = ([0, 1, 1], [400, 80, 15])\n",
    "    print(bounds_double, bounds_single)\n",
    "    peak_loc = np.argwhere(counts_to_fit==np.max(counts_to_fit))[0][0]\n",
    "    params_double, params_covariance_double = optimize.curve_fit(double_gaussian_fit, bins[:-1], counts_to_fit, p0_double, bounds = bounds_double)\n",
    "    params_single, params_covariance_single = optimize.curve_fit(gaussian_fit, bins[:-1], counts_to_fit, p0_single, bounds = bounds_single)\n",
    "    fit_single = gaussian_fit(bins_fit, params_single[0], params_single[1], params_single[2])\n",
    "    fit_double = double_gaussian_fit(bins_fit, params_double[0], params_double[1], params_double[2], params_double[3], params_double[4], params_double[5])\n",
    "    \n",
    "    mean_deviation = np.sqrt(np.mean((fit_single - fit_double)**2))\n",
    "    \n",
    "    if mean_deviation >5:\n",
    "        peaks = 2\n",
    "        if params_double[0]>=params_double[3]:\n",
    "            tall_peak = params_double[:3]\n",
    "            short_peak = params_double[3:]\n",
    "        else:\n",
    "            tall_peak = params_double[3:] \n",
    "            short_peak = params_double[:3]\n",
    "        \n",
    "        if params_double[1]<=params_double[4]:\n",
    "            left_peak = params_double[:3]\n",
    "            right_peak = params_double[3:]\n",
    "        else:\n",
    "            left_peak = params_double[3:] \n",
    "            right_peak = params_double[:3]\n",
    "        \n",
    "        a1, b1, c1 = left_peak\n",
    "        a2, b2, c2 = right_peak\n",
    "    \n",
    "        A = 1/c2**2-1/c1**2\n",
    "        B = 2*b1/c1**2-2*b2/c2**2\n",
    "        C = (b2/c2)**2-(b1/c1)**2+np.log(a1/a2)\n",
    "    \n",
    "        roots = np.roots([A,B,C])\n",
    "        intersection = np.max(gaussian_fit(roots, a1,b1,c1))\n",
    "        same_spot_value = intersection / short_peak[0]\n",
    "\n",
    "        if same_spot_value <= 0.5:\n",
    "            layer = 'organized'\n",
    "            nuclear_peak = left_peak[1]\n",
    "        else:\n",
    "            layer = 'disorganized'\n",
    "            nuclear_peak = left_peak[1]\n",
    "    else:\n",
    "        peaks = 1\n",
    "        same_spot_value = 'undef'\n",
    "        if params_single[2] > -0.372*(params_single[1]-min_layer_height) + 3.572:\n",
    "            layer = 'disorganized'\n",
    "            nuclear_peak = params_single[1]\n",
    "        else:\n",
    "            layer = 'organized'\n",
    "            nuclear_peak = params_single[1]\n",
    "    print(params_double, params_single, peak_loc_guess)\n",
    "\n",
    "    if (plot == True or save_name != False):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(bins[:-1], counts_to_fit, label = 'Nuclear Position')\n",
    "        if peaks == 1:\n",
    "            ax.plot(bins_fit, fit_single, label = 'Single Gaussian Fit')\n",
    "        elif peaks == 2:\n",
    "            ax.plot(bins_fit, fit_double, label = 'Double Gaussian Fit')\n",
    "        else:\n",
    "            return 'peaks suck'\n",
    "        \n",
    "        ax.legend(loc = 'upper right')\n",
    "        ax.set_ylabel('Number of nuclei')\n",
    "        ax.set_xlabel('Z Position ($\\mu$m)')\n",
    "        ax.set_xlim(0, 30)\n",
    "        ax2=ax.twinx()\n",
    "        ax2.plot(slice_heights, norm_intensities_actin, c='r')\n",
    "        ax2.set_ylabel('Actin Intensity (A.U.)')\n",
    "        ax2.axvline(x = min_layer_height, c='k', linestyle = '--', label = 'Layer Bounds')\n",
    "        ax2.axvline(x = max_layer_height, c = 'k', linestyle = '--')\n",
    "        ax2.axvline(x = actin_peak, c = 'k', linestyle = '--')\n",
    "        print(min_layer_height, max_layer_height)\n",
    "        fig.show\n",
    "        if save_name != False:\n",
    "            plt.savefig(save_name + '.pdf', bbox_inches = 'tight', pad_inches = 1)\n",
    "            \n",
    "    \n",
    "    return nuclear_peak, layer\n",
    "\n",
    "\n",
    "def terrain_map(df, image, **kwargs):\n",
    "    color = kwargs.get('color', 'magma_r')\n",
    "    save_name = kwargs.get('save_name', False)\n",
    "    invert = kwargs.get('invert', False)\n",
    "    df_cleared = clear_debris(df)\n",
    "    x_max, y_max, z_max, x_min, y_min, z_min, slice_heights = get_layer_position(df, image)\n",
    "    bottom, x1, x2, x3, x4 = layer_height_actin(df, image)\n",
    "    \n",
    "    xs = df_cleared['x'].values - x_min\n",
    "    ys = df_cleared['y'].values - y_min\n",
    "    zs = df_cleared['z'].values - z_min\n",
    "    vols = df_cleared['vol'].values\n",
    "    cross_sections = np.pi*(np.cbrt(vols*3/(4*np.pi)))**2 \n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    ax.scatter(xs, -ys, s = cross_sections/2, c = zs, cmap = color, vmin = bottom, vmax = bottom+20)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([0, x_max-x_min])\n",
    "    ax.set_ylim([-(y_max-y_min), 0])\n",
    "    if save_name != False:\n",
    "        plt.savefig(save_name + '.pdf', bbox_inches = 'tight', pad_inches = 1)\n",
    "    return\n",
    "\n",
    "def z_projection_with_cutoffs(df, image, **kwargs):\n",
    "    \n",
    "    section = kwargs.get('section', (False, False, False, False))\n",
    "    invert = kwargs.get('invert', False)\n",
    "    bottom, top, left, right = section\n",
    "    plot = kwargs.get('plot', False)\n",
    "    save_name = kwargs.get('save_name', False)\n",
    "    actin_channel = kwargs.get('actin_channel', 1)\n",
    "    \n",
    "    x_max, y_max, z_max, x_min, y_min, z_min, slice_heights = get_layer_position(df, image)\n",
    "    min_layer_height, max_layer_height, layer_height, actin_peak, norm_intensities_actin = layer_height_actin(df, image, actin_channel = actin_channel, invert = invert, section = section)\n",
    "    df_cleared = clear_debris(df)\n",
    "\n",
    "    density = len(df_cleared)/(x_max-x_min)**2*1000\n",
    "    if density <=2:\n",
    "        bot_cutoff = 0.5\n",
    "        top_cutoff = 0.6\n",
    "    elif density>=6:\n",
    "        bot_cutoff = 0.2\n",
    "        top_cutoff = 0.8\n",
    "    else:\n",
    "        bot_cutoff = 0.5-0.3*(density-2)/4\n",
    "        top_cutoff = 0.6+0.2*(density-2)/4\n",
    "    print(density, bot_cutoff, top_cutoff)\n",
    "    min_actin_slice = np.argwhere(norm_intensities_actin >= bot_cutoff)[0][0]\n",
    "    max_actin_slice = np.argwhere(norm_intensities_actin >= top_cutoff)[-1][0]\n",
    "    actin_peak_slice = np.argwhere(norm_intensities_actin == 1)[0][0]\n",
    "    \n",
    "    if plot == True and invert == True:\n",
    "        x = np.arange(512)  \n",
    "        ymin = min_actin_slice*np.ones_like(x)\n",
    "        ymax = max_actin_slice*np.ones_like(x)\n",
    "        peak = actin_peak_slice*np.ones_like(x)\n",
    "        fig, ax = plt.subplots(figsize = (8,2))\n",
    "        ax.imshow(np.sum(im[:,actin_channel,:,:], axis = 2)[::-1], origin = 'lower', cmap = 'Greys')\n",
    "        ax.plot(x,ymin, color = 'r')\n",
    "        ax.plot(x,ymax, color = 'r')\n",
    "        ax.plot(x,peak, color = 'r')\n",
    "        ax.plot()\n",
    "    else:\n",
    "        if plot == True and invert != True:\n",
    "            x = np.arange(512)  \n",
    "            mi, ma = z_projection_with_cutoffs(df, im)\n",
    "            ymin = min_actin_slice*np.ones_like(x)\n",
    "            ymax = max_actin_slice*np.ones_like(x)\n",
    "            peak = actin_peak_slice*np.ones_like(x)\n",
    "            fig, ax = plt.subplots(figsize = (8,2))\n",
    "            ax.imshow(np.sum(im[:,actin_channel,:,:], axis = 2), origin = 'lower',  cmap = 'Greys')\n",
    "            ax.plot(x,ymin, color = 'r')\n",
    "            ax.plot(x,ymax, color = 'r')\n",
    "            ax.plot(x,peak, color = 'r')\n",
    "    if save_name != False:\n",
    "        plt.savefig(save_name + '.pdf', bbox_inches = 'tight', pad_inches = 1)\n",
    "    print(min_actin_slice, max_actin_slice)\n",
    "    \n",
    "    \n",
    "    return min_actin_slice, max_actin_slice\n",
    "\n",
    "def layer_determination(df, image, **kwargs):\n",
    "    section = kwargs.get('section', (False, False, False, False))\n",
    "    invert = kwargs.get('invert', False)\n",
    "    actin_channel = kwargs.get('actin_channel', 1)\n",
    "    bottom, top, left, right = section\n",
    "    \n",
    "    x_max, y_max, z_max, x_min, y_min, z_min, slice_heights = get_layer_position(df, image)\n",
    "    min_layer_height, max_layer_height, layer_height, actin_peak, norm_intensities_actin = layer_height_actin(df, image, actin_channel = actin_channel, invert = invert, section = section)\n",
    "    equivalence, num_peaks = find_shoulders(df, image, actin_channel = actin_channel, invert = invert, section = section)\n",
    "    nuclear_peak, layer = nuclei_distribution(df, image, actin_channel = actin_channel, invert = invert, section = section)\n",
    "    \n",
    "    if top != False:\n",
    "        xlow = (x_max-x_min)*left/512+x_min\n",
    "        xhigh = (x_max-x_min)*right/512+x_min\n",
    "        ylow = (y_max-y_min)*bottom/512+y_min\n",
    "        yhigh = (y_max-y_min)*top/512+y_min\n",
    "    df_cleared = clear_debris(df)\n",
    "    if top != False:\n",
    "        df_cleared = df_cleared[(df_cleared['x'].values >= xlow)& \n",
    "                               (df_cleared['x'].values <= xhigh)&\n",
    "                               (df_cleared['y'].values >= ylow)&\n",
    "                               (df_cleared['y'].values <= yhigh)]\n",
    "\n",
    "    \n",
    "    actin_to_top = max_layer_height - actin_peak\n",
    "    actin_to_bottom = actin_peak - min_layer_height\n",
    "\n",
    "\n",
    "    peak_difference_rule = (actin_peak - nuclear_peak)>= 0\n",
    "    actin_peak_position_rule = (actin_to_top - actin_to_bottom)<0\n",
    "    deriv_peak_rule = num_peaks == 1 \n",
    "    \n",
    "    cells_above = np.sum(df_cleared['z']-z_min >= max_layer_height)\n",
    "    cells_inside = np.sum(df_cleared['z']-z_min < max_layer_height)\n",
    "    percentage_above = (cells_above/(cells_above+cells_inside)*100)\n",
    "    cell_density = (cells_inside+cells_above) / (x_max-x_min)**2*1000\n",
    "    \n",
    "\n",
    "    if layer == 'disorganized':\n",
    "        layer_classification = 'Disorganized'\n",
    "        \n",
    "    else:\n",
    "        if actin_peak_position_rule and peak_difference_rule:\n",
    "            if deriv_peak_rule:\n",
    "                layer_classification = 'Intermediate A' \n",
    "            elif equivalence < 1:\n",
    "                layer_classification = 'Intermediate B'\n",
    "            else:\n",
    "                layer_classification = 'Mature'\n",
    "        else:\n",
    "            layer_classification = 'Immature'\n",
    "    print(layer_height)\n",
    "   \n",
    "    return layer_classification, cells_above, cells_inside, percentage_above, cell_density\n",
    "\n",
    "def sub_classify(df, image, **kwargs):\n",
    "    plot = kwargs.get('plot', False)\n",
    "    save_name = kwargs.get('save_name',False)\n",
    "    invert = kwargs.get('invert', False)\n",
    "    actin_channel = kwargs.get('actin_channel', 1)\n",
    "    image = image_shuffle(image)\n",
    "    sub_image = image[:,:,:-2,:-2].copy()\n",
    "    sampling = kwargs.get('Sampling', 'Grid')\n",
    "    df_cleared = clear_debris(df)\n",
    "    x_max, y_max, z_max, x_min, y_min, z_min, slice_heights = get_layer_position(df, image)\n",
    "    min_layer_height, max_layer_height, layer_height, actin_peak, norm_intensities_actin = layer_height_actin(df, image, actin_channel = actin_channel, invert = invert)\n",
    "    layer_classification, cells_above, cells_inside, percentage_above, cell_density = layer_determination(df, image, actin_channel = actin_channel, invert = invert)\n",
    "    full_x = (x_max-x_min)*500/512\n",
    "    full_y = (y_max-y_min)*500/512\n",
    "    if sampling == 'Grid':\n",
    "        plot_to_make = np.zeros((500,500))\n",
    "        xs = np.linspace(x_min+full_x/10, x_min+9*full_x/10, 5)\n",
    "        ys = np.linspace(y_min+full_y/10, y_min+9*full_y/10, 5)\n",
    "        lts = np.linspace(0,400,5)\n",
    "        rbs = np.linspace(0,400,5)\n",
    "        a, b = np.meshgrid(xs, ys)\n",
    "        centers = np.vstack((a.ravel(), b.ravel())).transpose()\n",
    "        a, b = np.meshgrid(lts, rbs)\n",
    "        bounds = np.vstack((a.ravel(), b.ravel())).transpose()\n",
    "        all_sections_analyzed = []\n",
    "        for i in range(len(centers)):\n",
    "            a, b, c, d, e = layer_determination(df, image, actin_channel = actin_channel, invert = invert, section = (int(bounds[i,0]),int(bounds[i,0]+100), int(bounds[i,1]),int(bounds[i,1]+100)))\n",
    "            f, g, h, j, k = layer_height_actin(df, image, actin_channel = actin_channel, invert = invert, section = (int(bounds[i,0]),int(bounds[i,0]+100), int(bounds[i,1]),int(bounds[i,1]+100)))\n",
    "            all_sections_analyzed.append((a, b, c, h, layer_classification))\n",
    "            if a == 'Disorganized':\n",
    "                plot_to_make[int(bounds[i,0]):int(bounds[i,0]+100),int(bounds[i,1]):int(bounds[i,1]+100)] = 5*np.ones((100,100))\n",
    "            elif a == 'Mature':\n",
    "                plot_to_make[int(bounds[i,0]):int(bounds[i,0]+100),int(bounds[i,1]):int(bounds[i,1]+100)] = 4*np.ones((100,100))\n",
    "            elif a == 'Intermediate B':\n",
    "                plot_to_make[int(bounds[i,0]):int(bounds[i,0]+100),int(bounds[i,1]):int(bounds[i,1]+100)] = 3*np.ones((100,100))\n",
    "            elif a == 'Intermediate A':\n",
    "                plot_to_make[int(bounds[i,0]):int(bounds[i,0]+100),int(bounds[i,1]):int(bounds[i,1]+100)] = 2*np.ones((100,100))\n",
    "            elif a == 'Immature':\n",
    "                plot_to_make[int(bounds[i,0]):int(bounds[i,0]+100),int(bounds[i,1]):int(bounds[i,1]+100)] = np.ones((100,100))\n",
    "            else:\n",
    "                return print('How did this mess up?')\n",
    "        cmap = colors.ListedColormap(['lawngreen','forestgreen','darkturquoise','steelblue','orange'])\n",
    "        if plot == True or save_name != False:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(plot_to_make, cmap = cmap, alpha = 1, vmin = 1, vmax = 5)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            if save_name != False:\n",
    "                plt.savefig(save_name + '.pdf', bbox_inches = 'tight', pad_inches = 1)\n",
    "    elif sampling == 'Random':\n",
    "         return print('This method is not yet supported.')\n",
    "    else:\n",
    "        return print('This method is not yet supported.')\n",
    "    return all_sections_analyzed\n",
    "\n",
    "def nuclear_centroid_actin_overlay(df, image, **kwargs):\n",
    "    image = image_shuffle(image)\n",
    "    df_cleared = clear_debris(df)\n",
    "    x_max, y_max, z_max, x_min, y_min, z_min, slice_heights = get_layer_position(df, image)\n",
    "    actin_channel = kwargs.get('actin_channel', 1)\n",
    "    save_name = kwargs.get('save_name', False)\n",
    "    xy_proj_actin = np.sum(np.sum(image, axis = 3), axis = 2)[:,actin_channel].copy()\n",
    "    norm_intensities_actin = (xy_proj_actin-np.min(xy_proj_actin))/np.max(xy_proj_actin-np.min(xy_proj_actin))\n",
    "    min_actin_slice = np.argwhere(norm_intensities_actin >= 0.3)[0][0]\n",
    "    max_actin_slice = np.argwhere(norm_intensities_actin >= 0.5)[-1][0]\n",
    "    sum_proj_z = np.sum(image[min_actin_slice:max_actin_slice, actin_channel, :, :], axis = 0)\n",
    "    df_clear_in_layer = df_cleared[df_cleared['z']>(slice_heights[min_actin_slice]+z_min)]\n",
    "    df_clear_in_layer = df_clear_in_layer[df_clear_in_layer['z']<(slice_heights[max_actin_slice]+z_min)]\n",
    "    real_xs = (df_clear_in_layer['x'] - x_min)*sum_proj_z.shape[0]/(x_max-x_min)\n",
    "    real_ys = (df_clear_in_layer['y'] - y_min)*sum_proj_z.shape[1]/(y_max-y_min) \n",
    "    all_xs = (df['x'] - x_min)*sum_proj_z.shape[0]/(x_max-x_min)\n",
    "    all_ys = (df['y'] - y_min)*sum_proj_z.shape[1]/(y_max-y_min) \n",
    "    print(np.max(sum_proj_z), np.min(sum_proj_z), np.mean(sum_proj_z))\n",
    "    fig, ax = plt.subplots(figsize = (7,7))\n",
    "    ax.imshow(sum_proj_z, cmap = 'Greys', vmin = np.min(sum_proj_z), vmax = np.mean(sum_proj_z)*2, alpha = 0.4)\n",
    "    ax.scatter(all_xs, all_ys, c = 'r')\n",
    "    ax.scatter(real_xs, real_ys, c = 'k')\n",
    "    ax.set_xlim([0, sum_proj_z.shape[0]])\n",
    "    ax.set_ylim([0, sum_proj_z.shape[1]])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if save_name != False:\n",
    "        plt.savefig(save_name + '.pdf', bbox_inches = 'tight', pad_inches = 1)\n",
    "    return\n",
    "\n",
    "def xy_segmentation(df, image, **kwargs): \n",
    "    image = image_shuffle(image)\n",
    "    x_max, y_max, z_max, x_min, y_min, z_min, slice_heights = get_layer_position(df, image)\n",
    "    scale = (x_max - x_min)/image.shape[2]\n",
    "    df_cleared = clear_debris(df)\n",
    "    density = len(df_cleared)/(x_max-x_min)**2*1000\n",
    "    plot = kwargs.get('plot', False)\n",
    "    save_name = kwargs.get('save_name', False)\n",
    "    actin_channel = kwargs.get('actin_channel', 1)\n",
    "    dapi_channel = 0\n",
    "    invert = kwargs.get('invert', False)\n",
    "    \n",
    "    if invert != False:\n",
    "        xy_proj_actin = np.sum(np.sum(image, axis = 3), axis = 2)[:,actin_channel].copy()[::-1] \n",
    "    else:    \n",
    "        xy_proj_actin = np.sum(np.sum(image, axis = 3), axis = 2)[:,actin_channel].copy()\n",
    "    \n",
    "    norm_intensities_actin = (xy_proj_actin-np.min(xy_proj_actin))/np.max(xy_proj_actin-np.min(xy_proj_actin))\n",
    "    df_cleared = clear_debris(df)\n",
    "    density = len(df_cleared)/(x_max-x_min)**2*1000\n",
    "    if density <=2:\n",
    "        bot_cutoff = 0.5\n",
    "        top_cutoff = 0.6\n",
    "    elif density>=6:\n",
    "        bot_cutoff = 0.2\n",
    "        top_cutoff = 0.8\n",
    "    else:\n",
    "        bot_cutoff = 0.5-0.3*(density-2)/4\n",
    "        top_cutoff = 0.6+0.2*(density-2)/4\n",
    "    \n",
    "    start = np.argwhere(norm_intensities_actin >= bot_cutoff)[0][0]\n",
    "    end = np.argwhere(norm_intensities_actin >= top_cutoff)[-1][0]\n",
    "    \n",
    "    truncated_stack = image[start+3:end-3, :, :, :].copy()\n",
    "    \n",
    "    sum_project = np.sum(truncated_stack, axis = 0)\n",
    "    DNA = sum_project[dapi_channel,:,:]\n",
    "    Actin = sum_project[actin_channel,:,:]\n",
    "    \n",
    "    filtered = filters.gaussian(Actin)\n",
    "\n",
    "    thresh = filters.threshold_local(filtered, block_size = 55)\n",
    "    binary = filtered > thresh\n",
    "    \n",
    "    clean_image = morphology.remove_small_objects(morphology.remove_small_objects(binary))\n",
    "    dilate = morphology.dilation(morphology.dilation(morphology.dilation(clean_image)))\n",
    "    skeleton = morphology.skeletonize(dilate)\n",
    "    dilate_skeleton = morphology.dilation(morphology.dilation(morphology.dilation(morphology.dilation(skeleton))))\n",
    "    erosion_skeleton = morphology.erosion(morphology.erosion(morphology.erosion(dilate_skeleton)))\n",
    "    cell_mask = np.invert(erosion_skeleton)\n",
    "    clean_mask = clear_border(cell_mask)\n",
    "    distance_map = ndimage.distance_transform_edt(cell_mask)\n",
    "    local_peaks = peak_local_max(distance_map, min_distance = 10, threshold_abs = 2, indices=False)\n",
    "    markers = measure.label(local_peaks)\n",
    "    watershed_map = watershed(-distance_map, markers)\n",
    "    labeled_image = watershed_map * clean_mask\n",
    "    \n",
    "\n",
    "    cell_props = regionprops(labeled_image)\n",
    "\n",
    "    cell_ids = []\n",
    "    cell_areas = []\n",
    "    cell_centroid_rows = []\n",
    "    cell_centroid_cols = []\n",
    "    cell_perimeters = []\n",
    "    cell_eccentricities = []\n",
    "    cell_circularities = []\n",
    "        \n",
    "\n",
    "    for cell in cell_props:\n",
    "        cell_ids.append(cell.label)\n",
    "        cell_areas.append(cell.area * scale**2)\n",
    "        row, col = cell.centroid\n",
    "        cell_centroid_rows.append(row)\n",
    "        cell_centroid_cols.append(col)\n",
    "        cell_perimeters.append(cell.perimeter * scale)\n",
    "        cell_eccentricities.append(cell.eccentricity)\n",
    "        cell_circularities.append(4. * np.pi * cell.area / cell.perimeter**2)\n",
    "\n",
    "    \n",
    "    if save_name != False:\n",
    "        \n",
    "        data_dict = {'labels': cell_ids,\n",
    "                     'areas': cell_areas,\n",
    "                     'crows': cell_centroid_rows,\n",
    "                     'ccols': cell_centroid_cols,\n",
    "                     'perimeters': cell_perimeters,\n",
    "                     'eccentricities': cell_eccentricities,\n",
    "                     'circularities': cell_circularities}\n",
    "\n",
    "        df = pd.DataFrame(data_dict)\n",
    "        df.to_csv(save_name + '.csv')\n",
    "\n",
    "    return np.mean(cell_areas), np.mean(cell_perimeters), np.mean(cell_circularities)\n",
    "\n",
    "\n",
    "def fake_layers(**kwargs):\n",
    "    plot = kwargs.get('plot', False)\n",
    "    save_name = kwargs.get('save_name', False)\n",
    "    fake_type = kwargs.get('fake_type', False)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    underlying_layer = np.random.normal(7, 1, 300)\n",
    "    cells_on_top_double = np.random.normal(14, 1, 300)\n",
    "    cells_on_top_ball = np.random.normal(24, 5, 700)\n",
    "    cells_on_top_mountain = np.random.exponential(10, 700)+12\n",
    "        \n",
    "    double = np.concatenate([underlying_layer, cells_on_top_double])\n",
    "    mountain = np.concatenate([underlying_layer, cells_on_top_mountain])\n",
    "    ball = np.concatenate([underlying_layer, cells_on_top_ball])\n",
    "    \n",
    "\n",
    "    \n",
    "    if fake_type == False:\n",
    "        return \"That does not compute.\"\n",
    "    elif fake_type == 'double':\n",
    "        zs = double\n",
    "        cells_on_top = cells_on_top_double\n",
    "    elif fake_type == 'mountain':\n",
    "        zs = mountain\n",
    "        cells_on_top = cells_on_top_mountain\n",
    "    elif fake_type == 'ball':\n",
    "        zs = ball\n",
    "        cells_on_top = cells_on_top_ball\n",
    "    else:\n",
    "        return \"That does not compute.\"\n",
    "    \n",
    "    bins = np.linspace(0, 50, 51)\n",
    "    bins_fit = np.linspace(0, 50, 1000)\n",
    "    counts, bins_aux = np.histogram(zs, bins = bins)\n",
    "    counts_to_fit = smooth_array(counts)\n",
    "    \n",
    "    peak_height_guess = np.max(counts_to_fit)\n",
    "    peak_loc_guess = bins[np.argwhere(counts_to_fit==peak_height_guess)[0][0]]\n",
    "            \n",
    "            \n",
    "    p0_double = [peak_height_guess, peak_loc_guess, 2, 30, 2*peak_loc_guess, 5]\n",
    "    p0_single = [peak_height_guess, peak_loc_guess, 2]\n",
    "    print(p0_double, p0_single)\n",
    "    bounds_double = ([0, 1, 1, 0, 1, 1], [400, 80, 15, 400, 80, 15])\n",
    "    bounds_single = ([0, 1, 1], [400, 80, 15])\n",
    "    print(bounds_double, bounds_single)\n",
    "    peak_loc = np.argwhere(counts_to_fit==np.max(counts_to_fit))[0][0]\n",
    "    params_double, params_covariance_double = optimize.curve_fit(double_gaussian_fit, bins[:-1], counts_to_fit, p0_double, bounds = bounds_double)\n",
    "    params_single, params_covariance_single = optimize.curve_fit(gaussian_fit, bins[:-1], counts_to_fit, p0_single, bounds = bounds_single)\n",
    "    fit_single = gaussian_fit(bins_fit, params_single[0], params_single[1], params_single[2])\n",
    "    fit_double = double_gaussian_fit(bins_fit, params_double[0], params_double[1], params_double[2], params_double[3], params_double[4], params_double[5])\n",
    "    \n",
    "    mean_deviation = np.sqrt(np.mean((fit_single - fit_double)**2))\n",
    "    \n",
    "    if mean_deviation >5:\n",
    "        peaks = 2\n",
    "        if params_double[0]>=params_double[3]:\n",
    "            tall_peak = params_double[:3]\n",
    "            short_peak = params_double[3:]\n",
    "        else:\n",
    "            tall_peak = params_double[3:] \n",
    "            short_peak = params_double[:3]\n",
    "        \n",
    "        if params_double[1]<=params_double[4]:\n",
    "            left_peak = params_double[:3]\n",
    "            right_peak = params_double[3:]\n",
    "        else:\n",
    "            left_peak = params_double[3:] \n",
    "            right_peak = params_double[:3]\n",
    "        \n",
    "        a1, b1, c1 = left_peak\n",
    "        a2, b2, c2 = right_peak\n",
    "    \n",
    "        A = 1/c2**2-1/c1**2\n",
    "        B = 2*b1/c1**2-2*b2/c2**2\n",
    "        C = (b2/c2)**2-(b1/c1)**2+np.log(a1/a2)\n",
    "    \n",
    "        roots = np.roots([A,B,C])\n",
    "        intersection = np.max(gaussian_fit(roots, a1,b1,c1))\n",
    "        same_spot_value = intersection / short_peak[0]\n",
    "\n",
    "        if same_spot_value <= 0.5:\n",
    "            layer = 'organized'\n",
    "            nuclear_peak = left_peak[1]\n",
    "        else:\n",
    "            layer = 'disorganized'\n",
    "            nuclear_peak = left_peak[1]\n",
    "    else:\n",
    "        peaks = 1\n",
    "        same_spot_value = 'undef'\n",
    "        if params_single[2] > -0.372*(params_single[1]-min_layer_height) + 3.572:\n",
    "            layer = 'disorganized'\n",
    "            nuclear_peak = params_single[1]\n",
    "        else:\n",
    "            layer = 'organized'\n",
    "            nuclear_peak = params_single[1]\n",
    "    print(layer)\n",
    "    \n",
    "    counts_in, bins_in = np.histogram(underlying_layer, bins = bins)\n",
    "    counts_on, bins_on = np.histogram(cells_on_top, bins = bins)\n",
    "    \n",
    "    if (plot == True or save_name != False):\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        if peaks == 1:\n",
    "            ax.plot(bins_fit, fit_single, label = 'Single Gaussian Fit', linewidth = 3)\n",
    "        elif peaks == 2:\n",
    "            ax.plot(bins_fit, fit_double, label = 'Double Gaussian Fit', linewidth = 3)\n",
    "        else:\n",
    "            return 'peaks suck'\n",
    "        ax.scatter(bins[:-1], counts_in, label = 'Artificial Layer', c = 'orange')\n",
    "        ax.scatter(bins[:-1], counts_on, label = 'Artificial Cells on Top', c = 'g')\n",
    "        \n",
    "        ax.legend(loc = 'upper right')\n",
    "        ax.set_ylabel('Number of nuclei')\n",
    "        ax.set_xlabel('Z Position ($\\mu$m)')\n",
    "        ax.set_xlim(0, 50)\n",
    "        fig.show\n",
    "        \n",
    "        if save_name != False:\n",
    "            plt.savefig(save_name + '.pdf', bbox_inches = 'tight', pad_inches = 1)\n",
    "\n",
    "\n",
    "def batch_process(list_of_dfs, list_of_unshuffled_images, list_of_names, **kwargs):\n",
    "    save_name = kwargs.get('save_name', False)\n",
    "    actin_channel = kwargs.get('actin_channel', 1)\n",
    "    invert = kwargs.get('invert', False)\n",
    "    \n",
    "    list_of_cells_above = []\n",
    "    list_of_percent_above = []\n",
    "    list_of_cells_in = []\n",
    "    list_of_layer_class = []\n",
    "    list_of_cell_densities = []\n",
    "    list_of_layer_heights = []\n",
    "    list_of_bad_images = []\n",
    "    list_of_cell_areas = []\n",
    "    list_of_cell_perimeters = []\n",
    "    list_of_cell_circularities = []\n",
    "\n",
    "\n",
    "    for i in range(len(list_of_dfs)):\n",
    "        try:\n",
    "            df = list_of_dfs[i]\n",
    "            image = image_shuffle(list_of_unshuffled_images[i])\n",
    "                  \n",
    "            num_z, num_c, num_x, num_y = image.shape\n",
    "            df.columns = ['x', 'y', 'z', 'vol', 'positions']\n",
    "            x_max = df['positions'][0]\n",
    "            y_max = df['positions'][1]\n",
    "            z_max = df['positions'][2]\n",
    "            x_min = df['positions'][3]\n",
    "            y_min = df['positions'][4]\n",
    "            z_min = df['positions'][5]\n",
    "            slice_heights = np.linspace(0, z_max-z_min, num = num_z)\n",
    "\n",
    "            vols = df['vol'].values \n",
    "            bottom_vol = np.mean(vols)- (1*np.std(vols)) \n",
    "            df_cleared = df[df['vol']>=bottom_vol] \n",
    "\n",
    "            xy_proj_actin = np.sum(np.sum(image, axis = 3), axis = 2)[:,actin_channel]\n",
    "            \n",
    "            if invert == True:\n",
    "                xy_proj_actin = xy_proj_actin.copy()[::-1] \n",
    "            norm_intensities_actin = (xy_proj_actin-np.min(xy_proj_actin))/np.max(xy_proj_actin-np.min(xy_proj_actin)) \n",
    "            actin_peak = slice_heights[np.argwhere(norm_intensities_actin == np.max(norm_intensities_actin))][0][0] \n",
    "            density = len(df_cleared)/(x_max-x_min)**2*1000\n",
    "            if density <=2:\n",
    "                bot_cutoff = 0.5\n",
    "                top_cutoff = 0.6\n",
    "            elif density>=6:\n",
    "                bot_cutoff = 0.2\n",
    "                top_cutoff = 0.8\n",
    "            else:\n",
    "                bot_cutoff = 0.5-0.3*(density-2)/4\n",
    "                top_cutoff = 0.6+0.2*(density-2)/4\n",
    "            min_actin_slice = np.argwhere(norm_intensities_actin >= bot_cutoff)[0][0]\n",
    "            max_actin_slice = np.argwhere(norm_intensities_actin >= top_cutoff)[-1][0] \n",
    "            min_layer_height = slice_heights[min_actin_slice]\n",
    "            max_layer_height = slice_heights[max_actin_slice] \n",
    "            layer_height = max_layer_height-min_layer_height\n",
    "            actin_intensity_top = norm_intensities_actin[max_actin_slice] \n",
    "\n",
    "            zs = df_cleared['z'].values - z_min\n",
    "            bins = np.linspace(0, 50, 51)\n",
    "            bins_fit = np.linspace(0, 50, 1000)\n",
    "            counts, bins_aux = np.histogram(zs, bins = bins)\n",
    "            counts_to_fit = smooth_array(counts)\n",
    "            peak_height_guess = np.max(counts_to_fit)\n",
    "            peak_loc_guess = bins[np.argwhere(counts_to_fit==peak_height_guess)[0][0]]\n",
    "            p0_double = [peak_height_guess, peak_loc_guess, 2, 30, 2*peak_loc_guess, 5]\n",
    "            p0_single = [peak_height_guess, peak_loc_guess, 2]\n",
    "            bounds_double = ([0, 1, 1, 0, 1, 1], [400, 80, 15, 400, 80, 15])\n",
    "            bounds_single = ([0, 1, 1], [400, 80, 15])\n",
    "            peak_loc = np.argwhere(counts_to_fit==np.max(counts_to_fit))[0][0]\n",
    "            params_double, params_covariance_double = optimize.curve_fit(double_gaussian_fit, bins[:-1], counts_to_fit, p0_double, bounds = bounds_double)\n",
    "            params_single, params_covariance_single = optimize.curve_fit(gaussian_fit, bins[:-1], counts_to_fit, p0_single, bounds = bounds_single)\n",
    "            fit_single = gaussian_fit(bins_fit, params_single[0], params_single[1], params_single[2])\n",
    "            fit_double = double_gaussian_fit(bins_fit, params_double[0], params_double[1], params_double[2], params_double[3], params_double[4], params_double[5])\n",
    "\n",
    "            mean_deviation = np.sqrt(np.mean((fit_single - fit_double)**2))\n",
    "\n",
    "            if mean_deviation >5:\n",
    "                peaks = 2\n",
    "                if params_double[0]>=params_double[3]:\n",
    "                    tall_peak = params_double[:3]\n",
    "                    short_peak = params_double[3:]\n",
    "                else:\n",
    "                    tall_peak = params_double[3:] \n",
    "                    short_peak = params_double[:3]\n",
    "\n",
    "                if params_double[1]<=params_double[4]:\n",
    "                    left_peak = params_double[:3]\n",
    "                    right_peak = params_double[3:]\n",
    "                else:\n",
    "                    left_peak = params_double[3:] \n",
    "                    right_peak = params_double[:3]\n",
    "\n",
    "                a1, b1, c1 = left_peak\n",
    "                a2, b2, c2 = right_peak\n",
    "\n",
    "                A = 1/c2**2-1/c1**2\n",
    "                B = 2*b1/c1**2-2*b2/c2**2\n",
    "                C = (b2/c2)**2-(b1/c1)**2+np.log(a1/a2)\n",
    "\n",
    "                roots = np.roots([A,B,C])\n",
    "                intersection = np.max(gaussian_fit(roots, a1,b1,c1))\n",
    "                same_spot_value = intersection / short_peak[0]\n",
    "\n",
    "                if same_spot_value <= 0.5:\n",
    "                    layer = 'organized'\n",
    "                    nuclear_peak = left_peak[1]\n",
    "                else:\n",
    "                    layer = 'disorganized'\n",
    "                    nuclear_peak = left_peak[1]\n",
    "            else:\n",
    "                peaks = 1\n",
    "                same_spot_value = 'undef'\n",
    "                if params_single[2] > -0.372*(params_single[1]-min_layer_height) + 3.572:\n",
    "                    layer = 'disorganized'\n",
    "                    nuclear_peak = params_single[1]\n",
    "                else:\n",
    "                    layer = 'organized'\n",
    "                    nuclear_peak = params_single[1]\n",
    "                    \n",
    "            actin_profile_derivative = smooth_array(np.diff(norm_intensities_actin), window_size = 5)\n",
    "            peaks = signal.find_peaks(actin_profile_derivative, prominence = 0.008)\n",
    "            num_peaks = len(peaks[0])\n",
    "            \n",
    "            if len(peaks[0])==2:\n",
    "                equivalence = peaks[1]['prominences'][1]/peaks[1]['prominences'][0]\n",
    "            else:\n",
    "                equivalence = 'undef'\n",
    "\n",
    "\n",
    "            actin_to_top = max_layer_height - actin_peak\n",
    "            actin_to_bottom = actin_peak - min_layer_height\n",
    "            peak_difference_rule = (actin_peak - nuclear_peak)>= 0\n",
    "            actin_peak_position_rule = (actin_to_top - actin_to_bottom)<0\n",
    "            deriv_peak_rule = num_peaks == 1 \n",
    "\n",
    "            cells_above = np.sum(df_cleared['z']-z_min >= max_layer_height)\n",
    "            cells_inside = np.sum(df_cleared['z']-z_min < max_layer_height)\n",
    "            percentage_above = (cells_above/(cells_above+cells_inside)*100)\n",
    "            cell_density = (cells_inside+cells_above) / (x_max-x_min)**2*1000\n",
    "\n",
    "\n",
    "            if layer == 'disorganized':\n",
    "                layer_classification = 'Disorganized'\n",
    "                    \n",
    "            else:\n",
    "                if actin_peak_position_rule and peak_difference_rule:\n",
    "                    if deriv_peak_rule:\n",
    "                        layer_classification = 'Intermediate A' \n",
    "                    elif equivalence < 1:\n",
    "                        layer_classification = 'Intermediate B'\n",
    "                    else:\n",
    "                        layer_classification = 'Mature'\n",
    "                else:\n",
    "                    layer_classification = 'Immature'\n",
    "                    \n",
    "            area, perimeter, circularity = xy_segmentation(df, image)\n",
    "\n",
    "            list_of_cells_above.append(cells_above)\n",
    "            list_of_percent_above.append(percentage_above)\n",
    "            list_of_cells_in.append(cells_inside)\n",
    "            list_of_layer_class.append(layer_classification)\n",
    "            list_of_cell_densities.append(cell_density)\n",
    "            list_of_layer_heights.append(layer_height)\n",
    "            list_of_cell_areas.append(area)\n",
    "            list_of_cell_perimeters.append(perimeter)\n",
    "            list_of_cell_circularities.append(circularity)\n",
    "\n",
    "                \n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            list_of_bad_images.append(i)\n",
    "            continue\n",
    "    list_of_totals = []\n",
    "    for i in range(len(list_of_cells_in)):\n",
    "        list_of_totals.append(list_of_cells_in[i]+list_of_cells_above[i])\n",
    "    if len(list_of_bad_images)>0:\n",
    "        print('The following images would not complete processing: \\n', list_of_bad_images)\n",
    "        dict_list_of_names = np.delete(list_of_names, list_of_bad_images)\n",
    "    else:\n",
    "        dict_list_of_names = list_of_names\n",
    "\n",
    "    dict_data = {'names': dict_list_of_names,\n",
    "                 'Is this a layer?': list_of_layer_class,\n",
    "                 'cells in layer': list_of_cells_in,\n",
    "                 'cells above layer': list_of_cells_above,\n",
    "                 'total number of cells': list_of_totals,\n",
    "                 'cell densities': list_of_cell_densities,\n",
    "                 'layer height': list_of_layer_heights,\n",
    "                 '% above': list_of_percent_above,\n",
    "                 'average cell areas': list_of_cell_areas,\n",
    "                 'average cell perimeters': list_of_cell_perimeters,\n",
    "                 'average cell circularities': list_of_cell_circularities\n",
    "                }\n",
    "    \n",
    "    analyzed_df = pd.DataFrame(dict_data)\n",
    "    if save_name != False:\n",
    "        analyzed_df.to_csv(save_name + '.csv')\n",
    "        return analyzed_df\n",
    "    else:\n",
    "        return analyzed_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vj/prk0c9_j0274d7pv03rwf1bm0000gn/T/ipykernel_61196/2399805715.py:626: FutureWarning: indices argument is deprecated and will be removed in version 0.20. To avoid this warning, please do not use the indices argument. Please see peak_local_max documentation for more details.\n",
      "  local_peaks = peak_local_max(distance_map, min_distance = 10, threshold_abs = 2, indices=False)\n",
      "/var/folders/vj/prk0c9_j0274d7pv03rwf1bm0000gn/T/ipykernel_61196/2399805715.py:626: FutureWarning: indices argument is deprecated and will be removed in version 0.20. To avoid this warning, please do not use the indices argument. Please see peak_local_max documentation for more details.\n",
      "  local_peaks = peak_local_max(distance_map, min_distance = 10, threshold_abs = 2, indices=False)\n",
      "/var/folders/vj/prk0c9_j0274d7pv03rwf1bm0000gn/T/ipykernel_61196/2399805715.py:626: FutureWarning: indices argument is deprecated and will be removed in version 0.20. To avoid this warning, please do not use the indices argument. Please see peak_local_max documentation for more details.\n",
      "  local_peaks = peak_local_max(distance_map, min_distance = 10, threshold_abs = 2, indices=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3187808990478516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vj/prk0c9_j0274d7pv03rwf1bm0000gn/T/ipykernel_61196/2399805715.py:626: FutureWarning: indices argument is deprecated and will be removed in version 0.20. To avoid this warning, please do not use the indices argument. Please see peak_local_max documentation for more details.\n",
      "  local_peaks = peak_local_max(distance_map, min_distance = 10, threshold_abs = 2, indices=False)\n"
     ]
    }
   ],
   "source": [
    "toc = time.time()\n",
    "batch_process(list_of_dfs, list_of_unshuffled_images, list_of_names, actin_channel = 1, save_name = \"test_ALAN\")\n",
    "tic=time.time()\n",
    "print(tic-toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
